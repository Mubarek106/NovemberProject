{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries for the project\n",
    "import sys # for python library version\n",
    "import numpy as np # for scientific computing\n",
    "import pandas as pd # for data anaysis\n",
    "import matplotlib # for visualization\n",
    "import seaborn as sns # for visualization\n",
    "import sklearn # ML Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuesday DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 11:27:44) [MSC v.1900 64 bit (AMD64)]\n",
      "numpy: 1.15.2\n",
      "pandas: 0.23.4\n",
      "matplotlib: 3.0.1\n",
      "seaborn: 0.8.1\n",
      "sklearn: 0.20.0\n"
     ]
    }
   ],
   "source": [
    "print('Python: {}'.format(sys.version))  # Python version\n",
    "print('numpy: {}'.format(np.__version__))  # Numpy version\n",
    "print('pandas: {}'.format(pd.__version__))  # Pandas version\n",
    "print('matplotlib: {}'.format(matplotlib.__version__))  # Matplotlib version\n",
    "print('seaborn: {}'.format(sns.__version__))  # seaborn version\n",
    "print('sklearn: {}'.format(sklearn.__version__))  # sklearn version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No warning of any kind please!\n",
    "import warnings\n",
    "# will ignore any warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing first, we need to import/read the dataset and have a peak at it...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>Total Length of Bwd Packets</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>Fwd Packet Length Std</th>\n",
       "      <th>...</th>\n",
       "      <th>min_seg_size_forward</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88</td>\n",
       "      <td>640</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>440</td>\n",
       "      <td>358</td>\n",
       "      <td>220</td>\n",
       "      <td>0</td>\n",
       "      <td>62.857143</td>\n",
       "      <td>107.349008</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88</td>\n",
       "      <td>900</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>600</td>\n",
       "      <td>2944</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>132.287566</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88</td>\n",
       "      <td>1205</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2776</td>\n",
       "      <td>2830</td>\n",
       "      <td>1388</td>\n",
       "      <td>0</td>\n",
       "      <td>396.571429</td>\n",
       "      <td>677.274651</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Destination Port   Flow Duration   Total Fwd Packets  \\\n",
       "0                 88             640                   7   \n",
       "1                 88             900                   9   \n",
       "2                 88            1205                   7   \n",
       "\n",
       "    Total Backward Packets  Total Length of Fwd Packets  \\\n",
       "0                        4                          440   \n",
       "1                        4                          600   \n",
       "2                        4                         2776   \n",
       "\n",
       "    Total Length of Bwd Packets   Fwd Packet Length Max  \\\n",
       "0                           358                     220   \n",
       "1                          2944                     300   \n",
       "2                          2830                    1388   \n",
       "\n",
       "    Fwd Packet Length Min   Fwd Packet Length Mean   Fwd Packet Length Std  \\\n",
       "0                       0                62.857143              107.349008   \n",
       "1                       0                66.666667              132.287566   \n",
       "2                       0               396.571429              677.274651   \n",
       "\n",
       "    ...     min_seg_size_forward  Active Mean   Active Std   Active Max  \\\n",
       "0   ...                       20          0.0          0.0            0   \n",
       "1   ...                       20          0.0          0.0            0   \n",
       "2   ...                       20          0.0          0.0            0   \n",
       "\n",
       "   Active Min Idle Mean   Idle Std   Idle Max   Idle Min   Label  \n",
       "0           0       0.0        0.0          0          0  BENIGN  \n",
       "1           0       0.0        0.0          0          0  BENIGN  \n",
       "2           0       0.0        0.0          0          0  BENIGN  \n",
       "\n",
       "[3 rows x 79 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing the dataset to a variable\n",
    "data = pd.read_csv(\"K:/CIC-2017-dataset/CIC-IDS-2017/MachineLearningCVE/Tuesday-WorkingHours.pcap_ISCX.csv\")\n",
    "\n",
    "# displaying first 3 observations\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the data has been imported successfully. Now we need to know the number of observations and features we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have  445909  number of observations and  78  features for this dataset to predict type of traffic.\n"
     ]
    }
   ],
   "source": [
    "# dimensions of the data\n",
    "# where x will be no. of observation\n",
    "# and y will be features including 1 target variable\n",
    "x, y = data.shape   # x=445909   y=79\n",
    "\n",
    "print('We have ', x, ' number of observations and ', y-1, ' features for this dataset to predict type of traffic.')  # removing count of a target variable in 'y'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the datatypes of each feature and see if it needs any processing if the feature is not in its appropriate form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Destination Port                 int64\n",
       " Flow Duration                    int64\n",
       " Total Fwd Packets                int64\n",
       " Total Backward Packets           int64\n",
       "Total Length of Fwd Packets       int64\n",
       " Total Length of Bwd Packets      int64\n",
       " Fwd Packet Length Max            int64\n",
       " Fwd Packet Length Min            int64\n",
       " Fwd Packet Length Mean         float64\n",
       " Fwd Packet Length Std          float64\n",
       "Bwd Packet Length Max             int64\n",
       " Bwd Packet Length Min            int64\n",
       " Bwd Packet Length Mean         float64\n",
       " Bwd Packet Length Std          float64\n",
       "Flow Bytes/s                     object\n",
       " Flow Packets/s                  object\n",
       " Flow IAT Mean                  float64\n",
       " Flow IAT Std                   float64\n",
       " Flow IAT Max                     int64\n",
       " Flow IAT Min                     int64\n",
       "Fwd IAT Total                     int64\n",
       " Fwd IAT Mean                   float64\n",
       " Fwd IAT Std                    float64\n",
       " Fwd IAT Max                      int64\n",
       " Fwd IAT Min                      int64\n",
       "Bwd IAT Total                     int64\n",
       " Bwd IAT Mean                   float64\n",
       " Bwd IAT Std                    float64\n",
       " Bwd IAT Max                      int64\n",
       " Bwd IAT Min                      int64\n",
       "                                 ...   \n",
       " CWE Flag Count                   int64\n",
       " ECE Flag Count                   int64\n",
       " Down/Up Ratio                    int64\n",
       " Average Packet Size            float64\n",
       " Avg Fwd Segment Size           float64\n",
       " Avg Bwd Segment Size           float64\n",
       " Fwd Header Length.1              int64\n",
       "Fwd Avg Bytes/Bulk                int64\n",
       " Fwd Avg Packets/Bulk             int64\n",
       " Fwd Avg Bulk Rate                int64\n",
       " Bwd Avg Bytes/Bulk               int64\n",
       " Bwd Avg Packets/Bulk             int64\n",
       "Bwd Avg Bulk Rate                 int64\n",
       "Subflow Fwd Packets               int64\n",
       " Subflow Fwd Bytes                int64\n",
       " Subflow Bwd Packets              int64\n",
       " Subflow Bwd Bytes                int64\n",
       "Init_Win_bytes_forward            int64\n",
       " Init_Win_bytes_backward          int64\n",
       " act_data_pkt_fwd                 int64\n",
       " min_seg_size_forward             int64\n",
       "Active Mean                     float64\n",
       " Active Std                     float64\n",
       " Active Max                       int64\n",
       " Active Min                       int64\n",
       "Idle Mean                       float64\n",
       " Idle Std                       float64\n",
       " Idle Max                         int64\n",
       " Idle Min                         int64\n",
       " Label                           object\n",
       "Length: 79, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# datatypes of features\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 445909 entries, 0 to 445908\n",
      "Data columns (total 79 columns):\n",
      " Destination Port               445909 non-null int64\n",
      " Flow Duration                  445909 non-null int64\n",
      " Total Fwd Packets              445909 non-null int64\n",
      " Total Backward Packets         445909 non-null int64\n",
      "Total Length of Fwd Packets     445909 non-null int64\n",
      " Total Length of Bwd Packets    445909 non-null int64\n",
      " Fwd Packet Length Max          445909 non-null int64\n",
      " Fwd Packet Length Min          445909 non-null int64\n",
      " Fwd Packet Length Mean         445909 non-null float64\n",
      " Fwd Packet Length Std          445909 non-null float64\n",
      "Bwd Packet Length Max           445909 non-null int64\n",
      " Bwd Packet Length Min          445909 non-null int64\n",
      " Bwd Packet Length Mean         445909 non-null float64\n",
      " Bwd Packet Length Std          445909 non-null float64\n",
      "Flow Bytes/s                    445708 non-null object\n",
      " Flow Packets/s                 445909 non-null object\n",
      " Flow IAT Mean                  445909 non-null float64\n",
      " Flow IAT Std                   445909 non-null float64\n",
      " Flow IAT Max                   445909 non-null int64\n",
      " Flow IAT Min                   445909 non-null int64\n",
      "Fwd IAT Total                   445909 non-null int64\n",
      " Fwd IAT Mean                   445909 non-null float64\n",
      " Fwd IAT Std                    445909 non-null float64\n",
      " Fwd IAT Max                    445909 non-null int64\n",
      " Fwd IAT Min                    445909 non-null int64\n",
      "Bwd IAT Total                   445909 non-null int64\n",
      " Bwd IAT Mean                   445909 non-null float64\n",
      " Bwd IAT Std                    445909 non-null float64\n",
      " Bwd IAT Max                    445909 non-null int64\n",
      " Bwd IAT Min                    445909 non-null int64\n",
      "Fwd PSH Flags                   445909 non-null int64\n",
      " Bwd PSH Flags                  445909 non-null int64\n",
      " Fwd URG Flags                  445909 non-null int64\n",
      " Bwd URG Flags                  445909 non-null int64\n",
      " Fwd Header Length              445909 non-null int64\n",
      " Bwd Header Length              445909 non-null int64\n",
      "Fwd Packets/s                   445909 non-null float64\n",
      " Bwd Packets/s                  445909 non-null float64\n",
      " Min Packet Length              445909 non-null int64\n",
      " Max Packet Length              445909 non-null int64\n",
      " Packet Length Mean             445909 non-null float64\n",
      " Packet Length Std              445909 non-null float64\n",
      " Packet Length Variance         445909 non-null float64\n",
      "FIN Flag Count                  445909 non-null int64\n",
      " SYN Flag Count                 445909 non-null int64\n",
      " RST Flag Count                 445909 non-null int64\n",
      " PSH Flag Count                 445909 non-null int64\n",
      " ACK Flag Count                 445909 non-null int64\n",
      " URG Flag Count                 445909 non-null int64\n",
      " CWE Flag Count                 445909 non-null int64\n",
      " ECE Flag Count                 445909 non-null int64\n",
      " Down/Up Ratio                  445909 non-null int64\n",
      " Average Packet Size            445909 non-null float64\n",
      " Avg Fwd Segment Size           445909 non-null float64\n",
      " Avg Bwd Segment Size           445909 non-null float64\n",
      " Fwd Header Length.1            445909 non-null int64\n",
      "Fwd Avg Bytes/Bulk              445909 non-null int64\n",
      " Fwd Avg Packets/Bulk           445909 non-null int64\n",
      " Fwd Avg Bulk Rate              445909 non-null int64\n",
      " Bwd Avg Bytes/Bulk             445909 non-null int64\n",
      " Bwd Avg Packets/Bulk           445909 non-null int64\n",
      "Bwd Avg Bulk Rate               445909 non-null int64\n",
      "Subflow Fwd Packets             445909 non-null int64\n",
      " Subflow Fwd Bytes              445909 non-null int64\n",
      " Subflow Bwd Packets            445909 non-null int64\n",
      " Subflow Bwd Bytes              445909 non-null int64\n",
      "Init_Win_bytes_forward          445909 non-null int64\n",
      " Init_Win_bytes_backward        445909 non-null int64\n",
      " act_data_pkt_fwd               445909 non-null int64\n",
      " min_seg_size_forward           445909 non-null int64\n",
      "Active Mean                     445909 non-null float64\n",
      " Active Std                     445909 non-null float64\n",
      " Active Max                     445909 non-null int64\n",
      " Active Min                     445909 non-null int64\n",
      "Idle Mean                       445909 non-null float64\n",
      " Idle Std                       445909 non-null float64\n",
      " Idle Max                       445909 non-null int64\n",
      " Idle Min                       445909 non-null int64\n",
      " Label                          445909 non-null object\n",
      "dtypes: float64(22), int64(54), object(3)\n",
      "memory usage: 268.8+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation & Exploration of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset has 78 features and 1 target variable ' Label'. From 78 features, 60 are numeric and 18 are catrgorical. From 18 categorical, 10 are the features that always contain only one value 0. So we can delete that kind of redundant catrgorical columns whose values are always zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test if there any missing values in DataFrame. It turns out there are missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Destination Port                 0\n",
       " Flow Duration                    0\n",
       " Total Fwd Packets                0\n",
       " Total Backward Packets           0\n",
       "Total Length of Fwd Packets       0\n",
       " Total Length of Bwd Packets      0\n",
       " Fwd Packet Length Max            0\n",
       " Fwd Packet Length Min            0\n",
       " Fwd Packet Length Mean           0\n",
       " Fwd Packet Length Std            0\n",
       "Bwd Packet Length Max             0\n",
       " Bwd Packet Length Min            0\n",
       " Bwd Packet Length Mean           0\n",
       " Bwd Packet Length Std            0\n",
       "Flow Bytes/s                    201\n",
       " Flow Packets/s                   0\n",
       " Flow IAT Mean                    0\n",
       " Flow IAT Std                     0\n",
       " Flow IAT Max                     0\n",
       " Flow IAT Min                     0\n",
       "Fwd IAT Total                     0\n",
       " Fwd IAT Mean                     0\n",
       " Fwd IAT Std                      0\n",
       " Fwd IAT Max                      0\n",
       " Fwd IAT Min                      0\n",
       "Bwd IAT Total                     0\n",
       " Bwd IAT Mean                     0\n",
       " Bwd IAT Std                      0\n",
       " Bwd IAT Max                      0\n",
       " Bwd IAT Min                      0\n",
       "                               ... \n",
       " CWE Flag Count                   0\n",
       " ECE Flag Count                   0\n",
       " Down/Up Ratio                    0\n",
       " Average Packet Size              0\n",
       " Avg Fwd Segment Size             0\n",
       " Avg Bwd Segment Size             0\n",
       " Fwd Header Length.1              0\n",
       "Fwd Avg Bytes/Bulk                0\n",
       " Fwd Avg Packets/Bulk             0\n",
       " Fwd Avg Bulk Rate                0\n",
       " Bwd Avg Bytes/Bulk               0\n",
       " Bwd Avg Packets/Bulk             0\n",
       "Bwd Avg Bulk Rate                 0\n",
       "Subflow Fwd Packets               0\n",
       " Subflow Fwd Bytes                0\n",
       " Subflow Bwd Packets              0\n",
       " Subflow Bwd Bytes                0\n",
       "Init_Win_bytes_forward            0\n",
       " Init_Win_bytes_backward          0\n",
       " act_data_pkt_fwd                 0\n",
       " min_seg_size_forward             0\n",
       "Active Mean                       0\n",
       " Active Std                       0\n",
       " Active Max                       0\n",
       " Active Min                       0\n",
       "Idle Mean                         0\n",
       " Idle Std                         0\n",
       " Idle Max                         0\n",
       " Idle Min                         0\n",
       " Label                            0\n",
       "Length: 79, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing Observation which has any Missing Values in it...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(445909, 79)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# will delete observation if it has any missing values in any of the features.\n",
    "data.dropna()\n",
    "\n",
    "# shape of the data after deleting missing entries\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NO Missing Values...!! That's great!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(445909, 79)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deleting duplicates, except the first observation\n",
    "data.drop_duplicates(keep='first')\n",
    "\n",
    "# shape of the data after deleting duplicate entries\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NO Duplicates too..! Neat!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature statistics --- feature describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split the data in 2 parts. First part will contain all numerical features and second part will contain all binary or categorical features of the data. The target variable Cover_Type is excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting all numerical features from data\n",
    "num_fea = data[[\" Destination Port\",\n",
    "           \" Flow Duration\",\n",
    "           \" Total Fwd Packets\",\n",
    "           \" Total Backward Packets\",\n",
    "           \"Total Length of Fwd Packets\",\n",
    "           \" Total Length of Bwd Packets\",\n",
    "           \" Down/Up Ratio\",\n",
    "           \" Fwd Packet Length Max\",\n",
    "           \" Fwd Packet Length Min\",\n",
    "           \" Fwd Packet Length Mean\",\n",
    "           \" Fwd Packet Length Std\",\n",
    "           \"Bwd Packet Length Max\",\n",
    "           \" Bwd Packet Length Min\",\n",
    "           \" Bwd Packet Length Mean\",\n",
    "           \" Bwd Packet Length Std\",\n",
    "           \"Flow Bytes/s\",\n",
    "           \" Flow Packets/s\",\n",
    "           \" Flow IAT Mean\",\n",
    "           \" Flow IAT Std\",\n",
    "           \" Flow IAT Max\",\n",
    "           \" Flow IAT Min\", \n",
    "           \"Fwd IAT Total\",\n",
    "           \" Fwd IAT Mean\",\n",
    "           \" Fwd IAT Std\",\n",
    "           \" Fwd IAT Max\", \n",
    "           \" Fwd IAT Min\",\n",
    "           \"Bwd IAT Total\", \n",
    "           \" Bwd IAT Mean\",\n",
    "           \" Bwd IAT Std\", \n",
    "           \" Bwd IAT Max\", \n",
    "           \" Bwd IAT Min\", \n",
    "           \" Fwd Header Length\",\n",
    "           \" Bwd Header Length\",\n",
    "           \"Fwd Packets/s\",\n",
    "           \" Bwd Packets/s\", \n",
    "           \" Min Packet Length\",\n",
    "           \" Max Packet Length\",\n",
    "           \" Packet Length Mean\",\n",
    "           \" Packet Length Std\",\n",
    "           \" Packet Length Variance\",\n",
    "           \" Avg Bwd Segment Size\",\n",
    "           \" Average Packet Size\",\n",
    "           \" Avg Fwd Segment Size\",\n",
    "           \" Fwd Header Length\",\n",
    "           \"Subflow Fwd Packets\", \n",
    "           \" Subflow Fwd Bytes\", \n",
    "           \" Subflow Bwd Packets\",\n",
    "           \" Subflow Bwd Bytes\",\n",
    "           \"Init_Win_bytes_forward\", \n",
    "           \" Init_Win_bytes_backward\", \n",
    "           \" act_data_pkt_fwd\",\n",
    "           \" min_seg_size_forward\",\n",
    "           \"Active Mean\",\n",
    "           \" Active Std\",\n",
    "           \" Active Max\",\n",
    "           \" Active Min\",\n",
    "           \"Idle Mean\",\n",
    "           \" Idle Std\",\n",
    "           \" Idle Max\",\n",
    "           \" Idle Min\"\n",
    "\n",
    " ]]\n",
    "\n",
    "# extracting all binary/ categorical features from data\n",
    "binary_fea = data[[\"Fwd PSH Flags\",\n",
    "           \" Bwd PSH Flags\",  # 0\n",
    "           \" Fwd URG Flags\",  # 0\n",
    "           \" Bwd URG Flags\",  # 0\n",
    "           \"FIN Flag Count\", \n",
    "           \" SYN Flag Count\",\n",
    "           \" RST Flag Count\",\n",
    "           \" PSH Flag Count\",\n",
    "           \" ACK Flag Count\",\n",
    "           \" URG Flag Count\",\n",
    "           \" CWE Flag Count\",  # 0\n",
    "           \" ECE Flag Count\",\n",
    "           \"Fwd Avg Bytes/Bulk\",  # 0\n",
    "           \" Fwd Avg Packets/Bulk\", # 0\n",
    "           \" Fwd Avg Bulk Rate\",  # 0\n",
    "           \" Bwd Avg Bytes/Bulk\",  # 0\n",
    "           \" Bwd Avg Packets/Bulk\", # 0\n",
    "           \"Bwd Avg Bulk Rate\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(445909, 60)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_fea.shape     #  (445909,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>Total Length of Bwd Packets</th>\n",
       "      <th>Down/Up Ratio</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>...</th>\n",
       "      <th>act_data_pkt_fwd</th>\n",
       "      <th>min_seg_size_forward</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>445909.000000</td>\n",
       "      <td>4.459090e+05</td>\n",
       "      <td>445909.000000</td>\n",
       "      <td>445909.000000</td>\n",
       "      <td>4.459090e+05</td>\n",
       "      <td>4.459090e+05</td>\n",
       "      <td>445909.00000</td>\n",
       "      <td>445909.000000</td>\n",
       "      <td>445909.000000</td>\n",
       "      <td>445909.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>445909.000000</td>\n",
       "      <td>4.459090e+05</td>\n",
       "      <td>4.459090e+05</td>\n",
       "      <td>4.459090e+05</td>\n",
       "      <td>4.459090e+05</td>\n",
       "      <td>4.459090e+05</td>\n",
       "      <td>4.459090e+05</td>\n",
       "      <td>4.459090e+05</td>\n",
       "      <td>4.459090e+05</td>\n",
       "      <td>4.459090e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8878.375745</td>\n",
       "      <td>1.077944e+07</td>\n",
       "      <td>11.800473</td>\n",
       "      <td>13.907212</td>\n",
       "      <td>5.302105e+02</td>\n",
       "      <td>2.186324e+04</td>\n",
       "      <td>0.68745</td>\n",
       "      <td>173.346669</td>\n",
       "      <td>20.579979</td>\n",
       "      <td>48.528489</td>\n",
       "      <td>...</td>\n",
       "      <td>2.088341</td>\n",
       "      <td>-1.321786e+04</td>\n",
       "      <td>7.265964e+04</td>\n",
       "      <td>4.670517e+04</td>\n",
       "      <td>1.642092e+05</td>\n",
       "      <td>4.828426e+04</td>\n",
       "      <td>3.294459e+06</td>\n",
       "      <td>1.497105e+05</td>\n",
       "      <td>3.407025e+06</td>\n",
       "      <td>3.145407e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>19522.889728</td>\n",
       "      <td>2.955629e+07</td>\n",
       "      <td>867.072428</td>\n",
       "      <td>1172.161547</td>\n",
       "      <td>5.676904e+03</td>\n",
       "      <td>2.625768e+06</td>\n",
       "      <td>0.53444</td>\n",
       "      <td>472.450792</td>\n",
       "      <td>38.938350</td>\n",
       "      <td>113.195021</td>\n",
       "      <td>...</td>\n",
       "      <td>6.325197</td>\n",
       "      <td>2.666478e+06</td>\n",
       "      <td>6.205625e+05</td>\n",
       "      <td>3.601504e+05</td>\n",
       "      <td>1.049887e+06</td>\n",
       "      <td>5.649489e+05</td>\n",
       "      <td>1.258776e+07</td>\n",
       "      <td>1.982346e+06</td>\n",
       "      <td>1.293249e+07</td>\n",
       "      <td>1.240892e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.368707e+08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>53.000000</td>\n",
       "      <td>1.860000e+02</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>3.128800e+04</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.800000e+01</td>\n",
       "      <td>1.360000e+02</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>443.000000</td>\n",
       "      <td>4.668200e+05</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.500000e+02</td>\n",
       "      <td>3.360000e+02</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.200000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>65505.000000</td>\n",
       "      <td>1.200000e+08</td>\n",
       "      <td>206446.000000</td>\n",
       "      <td>276072.000000</td>\n",
       "      <td>2.428415e+06</td>\n",
       "      <td>6.270000e+08</td>\n",
       "      <td>35.00000</td>\n",
       "      <td>24820.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>4672.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1846.000000</td>\n",
       "      <td>1.380000e+02</td>\n",
       "      <td>1.070000e+08</td>\n",
       "      <td>2.410000e+07</td>\n",
       "      <td>1.070000e+08</td>\n",
       "      <td>1.070000e+08</td>\n",
       "      <td>1.200000e+08</td>\n",
       "      <td>7.590000e+07</td>\n",
       "      <td>1.200000e+08</td>\n",
       "      <td>1.200000e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Destination Port   Flow Duration   Total Fwd Packets  \\\n",
       "count      445909.000000    4.459090e+05       445909.000000   \n",
       "mean         8878.375745    1.077944e+07           11.800473   \n",
       "std         19522.889728    2.955629e+07          867.072428   \n",
       "min             0.000000   -4.000000e+00            1.000000   \n",
       "25%            53.000000    1.860000e+02            2.000000   \n",
       "50%            80.000000    3.128800e+04            2.000000   \n",
       "75%           443.000000    4.668200e+05            4.000000   \n",
       "max         65505.000000    1.200000e+08       206446.000000   \n",
       "\n",
       "        Total Backward Packets  Total Length of Fwd Packets  \\\n",
       "count            445909.000000                 4.459090e+05   \n",
       "mean                 13.907212                 5.302105e+02   \n",
       "std                1172.161547                 5.676904e+03   \n",
       "min                   0.000000                 0.000000e+00   \n",
       "25%                   1.000000                 4.000000e+00   \n",
       "50%                   2.000000                 6.800000e+01   \n",
       "75%                   2.000000                 1.500000e+02   \n",
       "max              276072.000000                 2.428415e+06   \n",
       "\n",
       "        Total Length of Bwd Packets   Down/Up Ratio   Fwd Packet Length Max  \\\n",
       "count                  4.459090e+05    445909.00000           445909.000000   \n",
       "mean                   2.186324e+04         0.68745              173.346669   \n",
       "std                    2.625768e+06         0.53444              472.450792   \n",
       "min                    0.000000e+00         0.00000                0.000000   \n",
       "25%                    0.000000e+00         0.00000                1.000000   \n",
       "50%                    1.360000e+02         1.00000               41.000000   \n",
       "75%                    3.360000e+02         1.00000               62.000000   \n",
       "max                    6.270000e+08        35.00000            24820.000000   \n",
       "\n",
       "        Fwd Packet Length Min   Fwd Packet Length Mean      ...       \\\n",
       "count           445909.000000            445909.000000      ...        \n",
       "mean                20.579979                48.528489      ...        \n",
       "std                 38.938350               113.195021      ...        \n",
       "min                  0.000000                 0.000000      ...        \n",
       "25%                  0.000000                 0.857143      ...        \n",
       "50%                  0.000000                37.000000      ...        \n",
       "75%                 41.000000                50.000000      ...        \n",
       "max               2065.000000              4672.000000      ...        \n",
       "\n",
       "        act_data_pkt_fwd   min_seg_size_forward   Active Mean    Active Std  \\\n",
       "count      445909.000000           4.459090e+05  4.459090e+05  4.459090e+05   \n",
       "mean            2.088341          -1.321786e+04  7.265964e+04  4.670517e+04   \n",
       "std             6.325197           2.666478e+06  6.205625e+05  3.601504e+05   \n",
       "min             0.000000          -5.368707e+08  0.000000e+00  0.000000e+00   \n",
       "25%             0.000000           2.000000e+01  0.000000e+00  0.000000e+00   \n",
       "50%             1.000000           2.000000e+01  0.000000e+00  0.000000e+00   \n",
       "75%             2.000000           3.200000e+01  0.000000e+00  0.000000e+00   \n",
       "max          1846.000000           1.380000e+02  1.070000e+08  2.410000e+07   \n",
       "\n",
       "         Active Max    Active Min     Idle Mean      Idle Std      Idle Max  \\\n",
       "count  4.459090e+05  4.459090e+05  4.459090e+05  4.459090e+05  4.459090e+05   \n",
       "mean   1.642092e+05  4.828426e+04  3.294459e+06  1.497105e+05  3.407025e+06   \n",
       "std    1.049887e+06  5.649489e+05  1.258776e+07  1.982346e+06  1.293249e+07   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "max    1.070000e+08  1.070000e+08  1.200000e+08  7.590000e+07  1.200000e+08   \n",
       "\n",
       "           Idle Min  \n",
       "count  4.459090e+05  \n",
       "mean   3.145407e+06  \n",
       "std    1.240892e+07  \n",
       "min    0.000000e+00  \n",
       "25%    0.000000e+00  \n",
       "50%    0.000000e+00  \n",
       "75%    0.000000e+00  \n",
       "max    1.200000e+08  \n",
       "\n",
       "[8 rows x 58 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_fea.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(445909, 18)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_fea.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The types of all traffics are [0]\n"
     ]
    }
   ],
   "source": [
    "listLabel = list(binary_fea[\"Bwd Avg Bulk Rate\"].drop_duplicates().values)\n",
    "print('\\n The types of all traffics are {}'.format(listLabel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can delete the redundant feature columns whose values are always zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_fea = binary_fea.drop([\" Bwd PSH Flags\",  # 0\n",
    "           \" Fwd URG Flags\",  # 0\n",
    "           \" Bwd URG Flags\",\n",
    "           \" CWE Flag Count\",\n",
    "           \"Fwd Avg Bytes/Bulk\",  # 0\n",
    "           \" Fwd Avg Packets/Bulk\", # 0\n",
    "           \" Fwd Avg Bulk Rate\",  # 0\n",
    "           \" Bwd Avg Bytes/Bulk\",  # 0\n",
    "           \" Bwd Avg Packets/Bulk\", # 0\n",
    "           \"Bwd Avg Bulk Rate\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fwd PSH Flags</th>\n",
       "      <th>FIN Flag Count</th>\n",
       "      <th>SYN Flag Count</th>\n",
       "      <th>RST Flag Count</th>\n",
       "      <th>PSH Flag Count</th>\n",
       "      <th>ACK Flag Count</th>\n",
       "      <th>URG Flag Count</th>\n",
       "      <th>ECE Flag Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>445909.000000</td>\n",
       "      <td>445909.000000</td>\n",
       "      <td>445909.000000</td>\n",
       "      <td>445909.000000</td>\n",
       "      <td>445909.000000</td>\n",
       "      <td>445909.000000</td>\n",
       "      <td>445909.000000</td>\n",
       "      <td>445909.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.060723</td>\n",
       "      <td>0.018380</td>\n",
       "      <td>0.060723</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>0.242597</td>\n",
       "      <td>0.291687</td>\n",
       "      <td>0.115091</td>\n",
       "      <td>0.000339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.238822</td>\n",
       "      <td>0.134323</td>\n",
       "      <td>0.238822</td>\n",
       "      <td>0.018338</td>\n",
       "      <td>0.428654</td>\n",
       "      <td>0.454540</td>\n",
       "      <td>0.319132</td>\n",
       "      <td>0.018399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Fwd PSH Flags  FIN Flag Count   SYN Flag Count   RST Flag Count  \\\n",
       "count  445909.000000   445909.000000    445909.000000    445909.000000   \n",
       "mean        0.060723        0.018380         0.060723         0.000336   \n",
       "std         0.238822        0.134323         0.238822         0.018338   \n",
       "min         0.000000        0.000000         0.000000         0.000000   \n",
       "25%         0.000000        0.000000         0.000000         0.000000   \n",
       "50%         0.000000        0.000000         0.000000         0.000000   \n",
       "75%         0.000000        0.000000         0.000000         0.000000   \n",
       "max         1.000000        1.000000         1.000000         1.000000   \n",
       "\n",
       "        PSH Flag Count   ACK Flag Count   URG Flag Count   ECE Flag Count  \n",
       "count    445909.000000    445909.000000    445909.000000    445909.000000  \n",
       "mean          0.242597         0.291687         0.115091         0.000339  \n",
       "std           0.428654         0.454540         0.319132         0.018399  \n",
       "min           0.000000         0.000000         0.000000         0.000000  \n",
       "25%           0.000000         0.000000         0.000000         0.000000  \n",
       "50%           0.000000         0.000000         0.000000         0.000000  \n",
       "75%           0.000000         1.000000         0.000000         0.000000  \n",
       "max           1.000000         1.000000         1.000000         1.000000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_fea.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our separate numerical DataFrame 'num_fea', it's time to feature-scale it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_fea = num_fea.rename(columns={\"Flow Bytes/s\":\"Flow Bytes\", \" Flow Packets/s\":\"Flow Packets\", \"Fwd Packets/s\":\"Fwd Packets\", \" Bwd Packets/s\":\"Bwd Packets\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "before we move to splitting our data to Train-Test Split is to scale the features to some specific range. but before we do this we will split the feature and target variables because we dont want to scale our target variable.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_fea = num_fea.drop(['Flow Bytes','Flow Packets'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can re-merge our two DataFrames into a new, X_scaled "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Distribution:\n",
    "Let's take a look how each class is distributed.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have uneven samples of traffic type, where BENIGN has the highest no. of observation.\n",
    "But we do have enough samples to train the model learning different patterns of each traffic types. We will see how models performs with these uneven amount of distributions in Model Evaluation section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Label\n",
       "BENIGN         432074\n",
       "FTP-Patator      7938\n",
       "SSH-Patator      5897\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grouping by forest cover type and calculating total occurance\n",
    "data.groupby(' Label').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data[' Label'] == 'BENIGN'] = 0\n",
    "data.loc[data[' Label'] == 'FTP-Patator'] = 1\n",
    "data.loc[data[' Label'] == 'SSH-Patator'] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can re-merge our two DataFrames into a new, X_scaled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([binary_fea, num_fea], axis=1, join='inner')    # 445909 Ã— 66\n",
    "# feeding our target variable to var 'y'\n",
    "y = data[' Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing feature scaling function\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# passing range to the function and then save it\n",
    "scaler = MinMaxScaler(feature_range = (0,1))\n",
    "\n",
    "\n",
    "# apply feature scaling to all features\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "#s_sample_2 = scaler.fit_transform(X2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Split\n",
    "Now our data is ready to be splitted into 75%-25% train-test set respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing train-test function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the data in 75%-25% train-test respectively with fixed state\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.25, random_state = 53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(334431, 66) (111478, 66)\n"
     ]
    }
   ],
   "source": [
    "# number of training observation\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lots of data to train and test on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now its time to feed our data to the models to see how each models performs using 2 different evaluation metrics accuracy and f1 score and see which model performs the best.\n",
    "\n",
    "But before that, we will train our data on training set and test the performance of the Benchmark model we discussed about in the start of the project. I will use 10 K-Fold CV to test the performance of our model. I had choosen Naive Bayes Classifier as my benchmark model and I am going to use Multimonial Naive Bayes classifier since we have a claasification problem to solve.\n",
    "\n",
    "The Evaluation Metric I am going to use are f1 score and accuracy to see how well our model performs.\n",
    "\n",
    "Accuracy is the measure of the correct predicted data divided by total number of observations hence giving a value ranging between 0 and 1, while 0 is no correctly predicted class whereas 1 is all correctly predicted class. We can multiply the result by 100 to get the accuracy score in terms of percent.\n",
    "\n",
    "F1 score is more useful than accuracy specially in the case where you have uneven amount of class distribution as in our case. It's the weighted average of Precision and Recall. Therefore, this score takes both false positives and false negatives into account.\n",
    "\n",
    "Accuracy works best if false positives and false negatives have similar cost. If the cost of false positives and false negatives are very different, itâ€™s better to look at both Precision and Recall or F1 score.\n",
    "\n",
    "First I will define a function which will train the models using training data and calculate model's performance using accuracy and f1 score. One sets of instruction for all models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "### defining function for training models and measuring performance \n",
    "\n",
    "# to measure performance\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# for calculating time elapsed\n",
    "import time\n",
    "\n",
    "# fucntion\n",
    "def model_evaluation(clf):\n",
    "    \n",
    "    # passing classifier to a variable\n",
    "    clf = clf\n",
    "    \n",
    "    # records time\n",
    "    t_start = time.time()\n",
    "    # classifier learning the model\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    # records time\n",
    "    t_end = time.time()\n",
    "    \n",
    "    \n",
    "    # records time\n",
    "    c_start = time.time()     \n",
    "    # Using 10 K-Fold CV on data, gives peroformance measures\n",
    "    accuracy  = cross_val_score(clf, X_train, y_train, cv = 10, scoring = 'accuracy')\n",
    "    f1_score = cross_val_score(clf, X_train, y_train, cv = 10, scoring = 'f1_macro')\n",
    "    # records the time\n",
    "    c_end = time.time()    \n",
    "    \n",
    "    \n",
    "    # calculating mean of all 10 observation's accuracy and f1, taking percent and rounding to two decimal places\n",
    "    acc_mean = np.round(accuracy.mean() * 100, 2)\n",
    "    f1_mean = np.round(f1_score.mean() * 100, 2)\n",
    "    \n",
    "    # substracts end time with start to give actual time taken in seconds\n",
    "    # divides by 60 to convert in minutes and rounds the answer to three decimal places\n",
    "    # time in training\n",
    "    t_time = np.round((t_end - t_start) / 60, 3)\n",
    "    # time for evaluating scores\n",
    "    c_time = np.round((c_end - c_start) / 60, 3)\n",
    "    \n",
    "    \n",
    "    # Removing traces of classifier\n",
    "    clf = None\n",
    "    \n",
    "    \n",
    "    # returns performance measure and time of the classifier \n",
    "    print(\"The accuracy score of this classifier on our training set is\", acc_mean,\"% and f1 score is\", f1_mean,\"% taking\", t_time,\"minutes to train and\", c_time,\n",
    "          \"minutes to evaluate cross validation and metric scores.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark Mode\n",
    "\n",
    "Now lets see the performance of MultinomialNB classifier on given training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of this classifier on our training set is 96.79 % and f1 score is 49.03 % taking 0.006 minutes to train and 0.14 minutes to evaluate cross validation and metric scores.\n"
     ]
    }
   ],
   "source": [
    "# importing Multinomial Naive Bayes classifier, one of the Naive Bayes classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# passing the model to function to get performance measures\n",
    "model_evaluation(MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of this classifier on our training set is 99.97 % and f1 score is 99.65 % taking 8.777 minutes to train and 184.721 minutes to evaluate cross validation and metric scores.\n"
     ]
    }
   ],
   "source": [
    "# importing K-Nearest Neighbors Classifier function\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model_evaluation(KNeighborsClassifier(n_jobs=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of this classifier on our training set is 100.0 % and f1 score is 99.97 % taking 0.037 minutes to train and 0.763 minutes to evaluate cross validation and metric scores.\n"
     ]
    }
   ],
   "source": [
    "# importing Random Forest function\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_evaluation(RandomForestClassifier(n_jobs=-1, random_state = 53))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of this classifier on our training set is 96.87 % and f1 score is 32.8 % taking 0.033 minutes to train and 0.335 minutes to evaluate cross validation and metric scores.\n"
     ]
    }
   ],
   "source": [
    "# importing Stochastic Gradient Descent Classifier function\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "model_evaluation(SGDClassifier(n_jobs=-1, random_state = 53))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of this classifier on our training set is 99.99 % and f1 score is 99.85 % taking 0.064 minutes to train and 1.232 minutes to evaluate cross validation and metric scores.\n"
     ]
    }
   ],
   "source": [
    "# importing AdaBoost classifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "model_evaluation(ExtraTreesClassifier(n_jobs=-1, random_state = 53))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of this classifier on our training set is 98.17 % and f1 score is 62.35 % taking 0.354 minutes to train and 6.076 minutes to evaluate cross validation and metric scores.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_evaluation(LogisticRegression(n_jobs = -1, random_state = 53))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing Model\n",
    "Out of 5 Models evaluated above and benchmark model, which performs better? Lets see all the scores of all the models in a table below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF performs here stunningly awesome, getting accuracy 100% and 99.97% of F1 score. taking seconds to train and couple of minutes running cross validation and metrics results. Also given its flexibility it has perofrmed so well with default params."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Model\n",
    "\n",
    "Since I had chosen default params above in Random Forest in training set, I will be tuning important param that might give us more better results. Later I will discuss about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of our final model Random Forest Classifier on our testing set is 99.995 % and f1 score is 99.933 %.\n"
     ]
    }
   ],
   "source": [
    "# importing EM scores for model performance measure\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# definning best chosen classifier\n",
    "clf = RandomForestClassifier(n_estimators = 50, random_state = 53)\n",
    "\n",
    "# training our model\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "# predicting unseen data\n",
    "predict = clf.predict(X_test)\n",
    "\n",
    "# calculating accuracy\n",
    "accuracy = accuracy_score(y_test, predict)\n",
    "\n",
    "# calculating f1 score\n",
    "f1_score = f1_score(y_test, predict, average = 'macro')\n",
    "\n",
    "# taking precentage and rounding to 3 places\n",
    "accuracy = np.round(accuracy * 100, 3)\n",
    "f1_score = np.round(f1_score * 100, 3)\n",
    "\n",
    "# cleaning traces\n",
    "clf = None\n",
    "\n",
    "# results\n",
    "print(\"The accuracy score of our final model Random Forest Classifier on our testing set is\", accuracy,\"% and f1 score is\", f1_score,\"%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
