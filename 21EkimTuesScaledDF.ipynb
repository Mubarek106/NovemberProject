{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#sklearn imports\n",
    "from sklearn.decomposition import PCA #Principal Component Analysis\n",
    "from sklearn.manifold import TSNE #T-Distributed Stochastic Neighbor Embedding\n",
    "from sklearn.cluster import KMeans #K-Means Clustering\n",
    "from sklearn.preprocessing import StandardScaler #used for 'Feature Scaling': failed\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler # used for feature rescaling : failed\n",
    "\n",
    "from sklearn.preprocessing import Normalizer # used for normalizing data : failed\n",
    "\n",
    "#plotly imports\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\anacondaa\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning:\n",
      "\n",
      "Columns (14,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(445909, 79)\n"
     ]
    }
   ],
   "source": [
    "#df is our original DataFrame of Tuesday\n",
    "df = pd.read_csv(\"K:/CIC-2017-dataset/CIC-IDS-2017/MachineLearningCVE/Tuesday-WorkingHours.pcap_ISCX.csv\")\n",
    "print(df.shape)        # (445909, 79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 445909 entries, 0 to 445908\n",
      "Data columns (total 79 columns):\n",
      " Destination Port               445909 non-null int64\n",
      " Flow Duration                  445909 non-null int64\n",
      " Total Fwd Packets              445909 non-null int64\n",
      " Total Backward Packets         445909 non-null int64\n",
      "Total Length of Fwd Packets     445909 non-null int64\n",
      " Total Length of Bwd Packets    445909 non-null int64\n",
      " Fwd Packet Length Max          445909 non-null int64\n",
      " Fwd Packet Length Min          445909 non-null int64\n",
      " Fwd Packet Length Mean         445909 non-null float64\n",
      " Fwd Packet Length Std          445909 non-null float64\n",
      "Bwd Packet Length Max           445909 non-null int64\n",
      " Bwd Packet Length Min          445909 non-null int64\n",
      " Bwd Packet Length Mean         445909 non-null float64\n",
      " Bwd Packet Length Std          445909 non-null float64\n",
      "Flow Bytes/s                    445708 non-null object\n",
      " Flow Packets/s                 445909 non-null object\n",
      " Flow IAT Mean                  445909 non-null float64\n",
      " Flow IAT Std                   445909 non-null float64\n",
      " Flow IAT Max                   445909 non-null int64\n",
      " Flow IAT Min                   445909 non-null int64\n",
      "Fwd IAT Total                   445909 non-null int64\n",
      " Fwd IAT Mean                   445909 non-null float64\n",
      " Fwd IAT Std                    445909 non-null float64\n",
      " Fwd IAT Max                    445909 non-null int64\n",
      " Fwd IAT Min                    445909 non-null int64\n",
      "Bwd IAT Total                   445909 non-null int64\n",
      " Bwd IAT Mean                   445909 non-null float64\n",
      " Bwd IAT Std                    445909 non-null float64\n",
      " Bwd IAT Max                    445909 non-null int64\n",
      " Bwd IAT Min                    445909 non-null int64\n",
      "Fwd PSH Flags                   445909 non-null int64\n",
      " Bwd PSH Flags                  445909 non-null int64\n",
      " Fwd URG Flags                  445909 non-null int64\n",
      " Bwd URG Flags                  445909 non-null int64\n",
      " Fwd Header Length              445909 non-null int64\n",
      " Bwd Header Length              445909 non-null int64\n",
      "Fwd Packets/s                   445909 non-null float64\n",
      " Bwd Packets/s                  445909 non-null float64\n",
      " Min Packet Length              445909 non-null int64\n",
      " Max Packet Length              445909 non-null int64\n",
      " Packet Length Mean             445909 non-null float64\n",
      " Packet Length Std              445909 non-null float64\n",
      " Packet Length Variance         445909 non-null float64\n",
      "FIN Flag Count                  445909 non-null int64\n",
      " SYN Flag Count                 445909 non-null int64\n",
      " RST Flag Count                 445909 non-null int64\n",
      " PSH Flag Count                 445909 non-null int64\n",
      " ACK Flag Count                 445909 non-null int64\n",
      " URG Flag Count                 445909 non-null int64\n",
      " CWE Flag Count                 445909 non-null int64\n",
      " ECE Flag Count                 445909 non-null int64\n",
      " Down/Up Ratio                  445909 non-null int64\n",
      " Average Packet Size            445909 non-null float64\n",
      " Avg Fwd Segment Size           445909 non-null float64\n",
      " Avg Bwd Segment Size           445909 non-null float64\n",
      " Fwd Header Length.1            445909 non-null int64\n",
      "Fwd Avg Bytes/Bulk              445909 non-null int64\n",
      " Fwd Avg Packets/Bulk           445909 non-null int64\n",
      " Fwd Avg Bulk Rate              445909 non-null int64\n",
      " Bwd Avg Bytes/Bulk             445909 non-null int64\n",
      " Bwd Avg Packets/Bulk           445909 non-null int64\n",
      "Bwd Avg Bulk Rate               445909 non-null int64\n",
      "Subflow Fwd Packets             445909 non-null int64\n",
      " Subflow Fwd Bytes              445909 non-null int64\n",
      " Subflow Bwd Packets            445909 non-null int64\n",
      " Subflow Bwd Bytes              445909 non-null int64\n",
      "Init_Win_bytes_forward          445909 non-null int64\n",
      " Init_Win_bytes_backward        445909 non-null int64\n",
      " act_data_pkt_fwd               445909 non-null int64\n",
      " min_seg_size_forward           445909 non-null int64\n",
      "Active Mean                     445909 non-null float64\n",
      " Active Std                     445909 non-null float64\n",
      " Active Max                     445909 non-null int64\n",
      " Active Min                     445909 non-null int64\n",
      "Idle Mean                       445909 non-null float64\n",
      " Idle Std                       445909 non-null float64\n",
      " Idle Max                       445909 non-null int64\n",
      " Idle Min                       445909 non-null int64\n",
      " Label                          445909 non-null object\n",
      "dtypes: float64(22), int64(54), object(3)\n",
      "memory usage: 268.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration/ Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we construct a new DataFrame, X that we can modify. X will begin as a 'copy' of the original DataFrame, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test if there any missing values in DataFrame. It turns out there are missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listLabel = list(X[\" Label\"].drop_duplicates().values)\n",
    "print('\\n The types of all traffics are {}'.format(listLabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\" Label\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benignTr = X.loc[X[\" Label\"] == 'BENIGN']\n",
    "ftpTr = X.loc[X[\" Label\"] == 'FTP-Patator']\n",
    "sshTr = X.loc[X[\" Label\"] == 'SSH-Patator']\n",
    "\n",
    "\n",
    "print ('\\n The number of Benign traffics = {}'.format(len(benignTr))) \n",
    "\n",
    "print ('\\n The number of FTP-Patator traffics = {}'.\\\n",
    "       format(len(ftpTr))) # \n",
    "print ('\\n The number of SSH-Patator traffics = {}'.\\\n",
    "       format(len(sshTr))) # \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\" Label\", axis=1)    #(445909, 78)\n",
    "y = df[\" Label\"]                #(445909,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, before we get into clustering our data, we just need to do one more thing: feature-scale our numerical variables.\n",
    "\n",
    "We need to do this because, while each of our categorical variables hold values of either 0 or 1, some of our numerical variables hold values like 2596 and 2785. If we were to leave our data like this, then K-Means Clustering would not give us such a nice result, since K-Means Clustering measures the euclidean distance between data-points. This means that, if we were to leave our numeical variables un-scaled, then most of the distance measured between points would be attributed to the larger numerical variables, rather than any of the categorical variables.\n",
    "\n",
    "To fix this problem we will scale all of our numerical variables through the use of sklearn's StandardScaler tool. This tool allows us to scale each numerical variable such that each numerical variable's mean becomes 0, and it's variance becomes 1. This is a good way to make sure that all of the numerical variables are on roughly the same scale that the categorical (binary) variables are on.\n",
    "\n",
    "But, to make sure we scale only our numerical variables -- and not our categorical variables --, we'll split our current DataFrame, X, into two other DataFrames: numer and cater; feature-scale. numer, then recombine the two DataFrames together again into a DataFrame that is suitable for clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numer is the DataFrame that holds all of X's numerical variables\n",
    "numer = X[[\" Destination Port\",\n",
    "           \" Flow Duration\",\n",
    "           \" Total Fwd Packets\",\n",
    "           \" Total Backward Packets\",\n",
    "           \"Total Length of Fwd Packets\",\n",
    "           \" Total Length of Bwd Packets\",\n",
    "           \" Down/Up Ratio\",\n",
    "           \" Fwd Packet Length Max\",\n",
    "           \" Fwd Packet Length Min\",\n",
    "           \" Fwd Packet Length Mean\",\n",
    "           \" Fwd Packet Length Std\",\n",
    "           \"Bwd Packet Length Max\",\n",
    "           \" Bwd Packet Length Min\",\n",
    "           \" Bwd Packet Length Mean\",\n",
    "           \" Bwd Packet Length Std\",\n",
    "           \"Flow Bytes/s\",\n",
    "           \" Flow Packets/s\",\n",
    "           \" Flow IAT Mean\",\n",
    "           \" Flow IAT Std\",\n",
    "           \" Flow IAT Max\",\n",
    "           \" Flow IAT Min\", \n",
    "           \"Fwd IAT Total\",\n",
    "           \" Fwd IAT Mean\",\n",
    "           \" Fwd IAT Std\",\n",
    "           \" Fwd IAT Max\", \n",
    "           \" Fwd IAT Min\",\n",
    "           \"Bwd IAT Total\", \n",
    "           \" Bwd IAT Mean\",\n",
    "           \" Bwd IAT Std\", \n",
    "           \" Bwd IAT Max\", \n",
    "           \" Bwd IAT Min\", \n",
    "           \" Fwd Header Length\",\n",
    "           \" Bwd Header Length\",\n",
    "           \"Fwd Packets/s\",\n",
    "           \" Bwd Packets/s\", \n",
    "           \" Min Packet Length\",\n",
    "           \" Max Packet Length\",\n",
    "           \" Packet Length Mean\",\n",
    "           \" Packet Length Std\",\n",
    "           \" Packet Length Variance\",\n",
    "           \" Avg Bwd Segment Size\",\n",
    "           \" Average Packet Size\",\n",
    "           \" Avg Fwd Segment Size\",\n",
    "           \" Fwd Header Length\",\n",
    "           \"Subflow Fwd Packets\", \n",
    "           \" Subflow Fwd Bytes\", \n",
    "           \" Subflow Bwd Packets\",\n",
    "           \" Subflow Bwd Bytes\",\n",
    "           \"Init_Win_bytes_forward\", \n",
    "           \" Init_Win_bytes_backward\", \n",
    "           \" act_data_pkt_fwd\",\n",
    "           \" min_seg_size_forward\",\n",
    "           \"Active Mean\",\n",
    "           \" Active Std\",\n",
    "           \" Active Max\",\n",
    "           \" Active Min\",\n",
    "           \"Idle Mean\",\n",
    "           \" Idle Std\",\n",
    "           \" Idle Max\",\n",
    "           \" Idle Min\"\n",
    "\n",
    " ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numer.shape     #  (445909,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cater is the DataFrame that holds all of X's categorical variables\n",
    "cater = X[[\"Fwd PSH Flags\",\n",
    "           \" Bwd PSH Flags\",  # 0\n",
    "           \" Fwd URG Flags\",  # 0\n",
    "           \" Bwd URG Flags\",  # 0\n",
    "           \"FIN Flag Count\", \n",
    "           \" SYN Flag Count\",\n",
    "           \" RST Flag Count\",\n",
    "           \" PSH Flag Count\",\n",
    "           \" ACK Flag Count\",\n",
    "           \" URG Flag Count\",\n",
    "           \" CWE Flag Count\",  # 0\n",
    "           \" ECE Flag Count\",\n",
    "           \"Fwd Avg Bytes/Bulk\",  # 0\n",
    "           \" Fwd Avg Packets/Bulk\", # 0\n",
    "           \" Fwd Avg Bulk Rate\",  # 0\n",
    "           \" Bwd Avg Bytes/Bulk\",  # 0\n",
    "           \" Bwd Avg Packets/Bulk\", # 0\n",
    "           \"Bwd Avg Bulk Rate\"]]  # 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cater.shape    # ((445909, 18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listLabel = list(cater[\"Bwd Avg Bulk Rate\"].drop_duplicates().values)\n",
    "print('\\n The types of all traffics are {}'.format(listLabel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can delete the redundant feature columns whose values are always zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cater = cater.drop([\" Bwd PSH Flags\",  # 0\n",
    "           \" Fwd URG Flags\",  # 0\n",
    "           \" Bwd URG Flags\",\n",
    "           \" CWE Flag Count\",\n",
    "           \"Fwd Avg Bytes/Bulk\",  # 0\n",
    "           \" Fwd Avg Packets/Bulk\", # 0\n",
    "           \" Fwd Avg Bulk Rate\",  # 0\n",
    "           \" Bwd Avg Bytes/Bulk\",  # 0\n",
    "           \" Bwd Avg Packets/Bulk\", # 0\n",
    "           \"Bwd Avg Bulk Rate\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cater.shape     # (445909, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cater.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our separate numerical DataFrame, it's time to feature-scale it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize our scaler\n",
    "#scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale each column in numer: failed\n",
    "#numer[' Destination Port'] = pd.DataFrame(scaler.fit_transform(numer[' Destination Port']))\n",
    "# or numer = pd.DataFrame(scaler.fit_transform(numer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numer = numer.rename(columns={\"Flow Bytes/s\":\"Flow Bytes\", \" Flow Packets/s\":\"Flow Packets\", \"Fwd Packets/s\":\"Fwd Packets\", \" Bwd Packets/s\":\"Bwd Packets\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Failed\n",
    "# Input contains NaN, infinity or a value too large for dtype('float64')\n",
    "# numer[\"Flow Bytes\"] = preprocessing.scale(numer[\"Flow Bytes\"])\n",
    "\n",
    "# Failed\n",
    "# numer[\"Flow Packets\"] = preprocessing.scale(numer[\"Flow Packets\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numer = numer.drop(['Flow Bytes','Flow Packets'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numer[\"Fwd Packets\"] = preprocessing.scale(numer[\"Fwd Packets\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numer[\"Bwd Packets\"] = preprocessing.scale(numer[\"Bwd Packets\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numer[' Destination Port']=preprocessing.scale(numer[' Destination Port'])\n",
    "numer[' Flow Duration']=preprocessing.scale(numer[' Flow Duration'])\n",
    "numer[[' Total Fwd Packets',\n",
    "       ' Total Backward Packets']]=preprocessing.scale(numer[[' Total Fwd Packets',' Total Backward Packets']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numer[[ \"Total Length of Fwd Packets\",\n",
    "           \" Total Length of Bwd Packets\",\n",
    "           \" Down/Up Ratio\",\n",
    "           \" Fwd Packet Length Max\",\n",
    "           \" Fwd Packet Length Min\",\n",
    "           \" Fwd Packet Length Mean\",\n",
    "           \" Fwd Packet Length Std\",\n",
    "           \"Bwd Packet Length Max\",\n",
    "           \" Bwd Packet Length Min\",\n",
    "           \" Bwd Packet Length Mean\",\n",
    "           ]]=preprocessing.scale(numer[[ \"Total Length of Fwd Packets\",\n",
    "           \" Total Length of Bwd Packets\",\n",
    "           \" Down/Up Ratio\",\n",
    "           \" Fwd Packet Length Max\",\n",
    "           \" Fwd Packet Length Min\",\n",
    "           \" Fwd Packet Length Mean\",\n",
    "           \" Fwd Packet Length Std\",\n",
    "           \"Bwd Packet Length Max\",\n",
    "           \" Bwd Packet Length Min\",\n",
    "           \" Bwd Packet Length Mean\",\n",
    "           ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numer[[\" Bwd Packet Length Std\"]]=preprocessing.scale(numer[[\" Bwd Packet Length Std\"]])\n",
    "numer[\" Flow IAT Mean\"] = preprocessing.scale(numer[\" Flow IAT Mean\"])\n",
    "numer[\" Flow IAT Std\"] = preprocessing.scale(numer[\" Flow IAT Std\"])\n",
    "numer[\" Flow IAT Max\"] = preprocessing.scale(numer[\" Flow IAT Max\"])\n",
    "numer[\" Flow IAT Min\"] = preprocessing.scale(numer[\" Flow IAT Min\"])\n",
    "numer[\"Fwd IAT Total\"] = preprocessing.scale(numer[\"Fwd IAT Total\"])\n",
    "numer[\" Fwd IAT Mean\"] = preprocessing.scale(numer[\" Fwd IAT Mean\"])\n",
    "numer[\" Fwd IAT Std\"] = preprocessing.scale(numer[\" Fwd IAT Std\"])\n",
    "numer[\" Fwd IAT Max\"] = preprocessing.scale(numer[\" Fwd IAT Max\"])\n",
    "numer[\" Fwd IAT Min\"] = preprocessing.scale(numer[\" Fwd IAT Min\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numer[\"Bwd IAT Total\"] = preprocessing.scale(numer[\"Bwd IAT Total\"])\n",
    "numer[\" Bwd IAT Mean\"] = preprocessing.scale(numer[\" Bwd IAT Mean\"])\n",
    "numer[\" Bwd IAT Std\"] = preprocessing.scale(numer[\" Bwd IAT Std\"])\n",
    "numer[\" Bwd IAT Max\"] = preprocessing.scale(numer[\" Bwd IAT Max\"])\n",
    "numer[\" Bwd IAT Min\"] = preprocessing.scale(numer[\" Bwd IAT Min\"])\n",
    "numer[\" Fwd Header Length\"] = preprocessing.scale(numer[\" Fwd Header Length\"])\n",
    "numer[\" Bwd Header Length\"] = preprocessing.scale(numer[\" Bwd Header Length\"])\n",
    "numer[\" Min Packet Length\"] = preprocessing.scale(numer[\" Min Packet Length\"])\n",
    "numer[\" Max Packet Length\"] = preprocessing.scale(numer[\" Max Packet Length\"])\n",
    "numer[\" Packet Length Mean\"] = preprocessing.scale(numer[\" Packet Length Mean\"])\n",
    "numer[\" Packet Length Std\"] = preprocessing.scale(numer[\" Packet Length Std\"])\n",
    "numer[\" Packet Length Variance\"] = preprocessing.scale(numer[\" Packet Length Variance\"])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numer[\" Avg Bwd Segment Size\"] = preprocessing.scale(numer[\" Avg Bwd Segment Size\"])\n",
    "numer[\" Average Packet Size\"] = preprocessing.scale(numer[\" Average Packet Size\"])\n",
    "numer[\" Avg Fwd Segment Size\"] = preprocessing.scale(numer[\" Avg Fwd Segment Size\"])\n",
    "numer[\" Fwd Header Length\"] = preprocessing.scale(numer[\" Fwd Header Length\"])\n",
    "numer[\"Subflow Fwd Packets\"] = preprocessing.scale(numer[\"Subflow Fwd Packets\"])\n",
    "numer[\" Subflow Fwd Bytes\"] = preprocessing.scale(numer[\" Subflow Fwd Bytes\"])\n",
    "numer[\" Subflow Bwd Packets\"] = preprocessing.scale(numer[\" Subflow Bwd Packets\"])\n",
    "numer[\" Subflow Bwd Bytes\"] = preprocessing.scale(numer[\" Subflow Bwd Bytes\"])\n",
    "numer[\"Init_Win_bytes_forward\"] = preprocessing.scale(numer[\"Init_Win_bytes_forward\"])\n",
    "numer[\" Init_Win_bytes_backward\"] = preprocessing.scale(numer[\" Init_Win_bytes_backward\"])\n",
    "numer[\" act_data_pkt_fwd\"] = preprocessing.scale(numer[\" act_data_pkt_fwd\"])\n",
    "numer[\" min_seg_size_forward\"] = preprocessing.scale(numer[\" min_seg_size_forward\"])\n",
    "numer[\"Active Mean\"] = preprocessing.scale(numer[\"Active Mean\"])\n",
    "numer[\" Active Std\"] = preprocessing.scale(numer[\" Active Std\"])\n",
    "numer[\" Active Max\"] = preprocessing.scale(numer[\" Active Max\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numer[\" Active Min\"] = preprocessing.scale(numer[\" Active Min\"])\n",
    "numer[\"Idle Mean\"] = preprocessing.scale(numer[\"Idle Mean\"])\n",
    "numer[\" Idle Std\"] = preprocessing.scale(numer[\" Idle Std\"])\n",
    "numer[\" Idle Max\"] = preprocessing.scale(numer[\" Idle Max\"])\n",
    "numer[\" Idle Min\"] = preprocessing.scale(numer[\" Idle Min\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can re-merge our two DataFrames into a new, scaled X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([numer, cater], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv(\"K:/exportedFiles/TuesScaledDF.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time to build our clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this kernel, we will be visualizing only three different clusters on our data. I chose three because I found it to be a good number of clusters to help us visualize our data in a non-complicated way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize our model\n",
    "kmeans = KMeans(n_clusters=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit our model\n",
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find which cluster each data-point belongs to\n",
    "clusters = kmeans.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the cluster vector to our DataFrame, X\n",
    "X[\"Cluster\"] = clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our clusters, we can begin visualizing our data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
