{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries for the project\n",
    "import sys # for python library version\n",
    "import numpy as np # for scientific computing\n",
    "import pandas as pd # for data anaysis\n",
    "import matplotlib # for visualization\n",
    "import seaborn as sns # for visualization\n",
    "import sklearn # ML Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\anacondaa\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (14,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>Total Length of Bwd Packets</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>Fwd Packet Length Std</th>\n",
       "      <th>...</th>\n",
       "      <th>min_seg_size_forward</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>38308</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>389</td>\n",
       "      <td>479</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>326</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>15.636364</td>\n",
       "      <td>31.449238</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88</td>\n",
       "      <td>1095</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>3150</td>\n",
       "      <td>3150</td>\n",
       "      <td>1575</td>\n",
       "      <td>0</td>\n",
       "      <td>315.000000</td>\n",
       "      <td>632.561635</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Destination Port   Flow Duration   Total Fwd Packets  \\\n",
       "0                 80           38308                   1   \n",
       "1                389             479                  11   \n",
       "2                 88            1095                  10   \n",
       "\n",
       "    Total Backward Packets  Total Length of Fwd Packets  \\\n",
       "0                        1                            6   \n",
       "1                        5                          172   \n",
       "2                        6                         3150   \n",
       "\n",
       "    Total Length of Bwd Packets   Fwd Packet Length Max  \\\n",
       "0                             6                       6   \n",
       "1                           326                      79   \n",
       "2                          3150                    1575   \n",
       "\n",
       "    Fwd Packet Length Min   Fwd Packet Length Mean   Fwd Packet Length Std  \\\n",
       "0                       6                 6.000000                0.000000   \n",
       "1                       0                15.636364               31.449238   \n",
       "2                       0               315.000000              632.561635   \n",
       "\n",
       "    ...     min_seg_size_forward  Active Mean   Active Std   Active Max  \\\n",
       "0   ...                       20          0.0          0.0            0   \n",
       "1   ...                       32          0.0          0.0            0   \n",
       "2   ...                       32          0.0          0.0            0   \n",
       "\n",
       "   Active Min Idle Mean   Idle Std   Idle Max   Idle Min   Label  \n",
       "0           0       0.0        0.0          0          0  BENIGN  \n",
       "1           0       0.0        0.0          0          0  BENIGN  \n",
       "2           0       0.0        0.0          0          0  BENIGN  \n",
       "\n",
       "[3 rows x 79 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing the dataset to a variable\n",
    "data = pd.read_csv(\"K:/CIC-2017-dataset/CIC-IDS-2017/MachineLearningCVE/Wednesday-workingHours.pcap_ISCX.csv\")\n",
    "\n",
    "# displaying first 3 observations\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Getting Started\n",
    "\n",
    "First thing first, we need to import/read the dataset and have a peak at it...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the data has been imported successfully. Now we need to know the number of observations and features we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can delete the redundant feature columns whose values are always zero\n",
    "data = data.drop([\" Bwd PSH Flags\",  # 0\n",
    "           \" Fwd URG Flags\",  # 0\n",
    "           \" Bwd URG Flags\",\n",
    "           \" CWE Flag Count\",\n",
    "           \"Fwd Avg Bytes/Bulk\",  # 0\n",
    "           \" Fwd Avg Packets/Bulk\", # 0\n",
    "           \" Fwd Avg Bulk Rate\",  # 0\n",
    "           \" Bwd Avg Bytes/Bulk\",  # 0\n",
    "           \" Bwd Avg Packets/Bulk\", # 0\n",
    "           \"Bwd Avg Bulk Rate\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also delete NAN values\n",
    "data = data.drop(['Flow Bytes/s',' Flow Packets/s'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have  692703  number of observations and  66  features for this dataset to predict type of traffic.\n"
     ]
    }
   ],
   "source": [
    "# dimensions of the data\n",
    "# where x will be no. of observation\n",
    "# and y will be features including 1 target variable\n",
    "x, y = data.shape   # x=692703     y=67\n",
    "\n",
    "print('We have ', x, ' number of observations and ', y-1, ' features for this dataset to predict type of traffic.')  # removing count of a target variable in 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Label\n",
       "BENIGN              440031\n",
       "DoS GoldenEye        10293\n",
       "DoS Hulk            231073\n",
       "DoS Slowhttptest      5499\n",
       "DoS slowloris         5796\n",
       "Heartbleed              11\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grouping by forest cover type and calculating total occurance\n",
    "data.groupby(' Label').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data[' Label'] = data[' Label'].map({'BENIGN': 0, \n",
    "                                     'DoS Hulk': 1,\n",
    "                                     'DoS GoldenEye':2,\n",
    "                                     'DoS slowloris':3,\n",
    "                                     'DoS Slowhttptest':4,\n",
    "                                     'Heartbleed':5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    440031\n",
       "1    231073\n",
       "2     10293\n",
       "3      5796\n",
       "4      5499\n",
       "5        11\n",
       "Name:  Label, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attack Class Distribution\n",
    "data[' Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 692703 entries, 0 to 692702\n",
      "Data columns (total 67 columns):\n",
      " Destination Port               692703 non-null int64\n",
      " Flow Duration                  692703 non-null int64\n",
      " Total Fwd Packets              692703 non-null int64\n",
      " Total Backward Packets         692703 non-null int64\n",
      "Total Length of Fwd Packets     692703 non-null int64\n",
      " Total Length of Bwd Packets    692703 non-null int64\n",
      " Fwd Packet Length Max          692703 non-null int64\n",
      " Fwd Packet Length Min          692703 non-null int64\n",
      " Fwd Packet Length Mean         692703 non-null float64\n",
      " Fwd Packet Length Std          692703 non-null float64\n",
      "Bwd Packet Length Max           692703 non-null int64\n",
      " Bwd Packet Length Min          692703 non-null int64\n",
      " Bwd Packet Length Mean         692703 non-null float64\n",
      " Bwd Packet Length Std          692703 non-null float64\n",
      " Flow IAT Mean                  692703 non-null float64\n",
      " Flow IAT Std                   692703 non-null float64\n",
      " Flow IAT Max                   692703 non-null int64\n",
      " Flow IAT Min                   692703 non-null int64\n",
      "Fwd IAT Total                   692703 non-null int64\n",
      " Fwd IAT Mean                   692703 non-null float64\n",
      " Fwd IAT Std                    692703 non-null float64\n",
      " Fwd IAT Max                    692703 non-null int64\n",
      " Fwd IAT Min                    692703 non-null int64\n",
      "Bwd IAT Total                   692703 non-null int64\n",
      " Bwd IAT Mean                   692703 non-null float64\n",
      " Bwd IAT Std                    692703 non-null float64\n",
      " Bwd IAT Max                    692703 non-null int64\n",
      " Bwd IAT Min                    692703 non-null int64\n",
      "Fwd PSH Flags                   692703 non-null int64\n",
      " Fwd Header Length              692703 non-null int64\n",
      " Bwd Header Length              692703 non-null int64\n",
      "Fwd Packets/s                   692703 non-null float64\n",
      " Bwd Packets/s                  692703 non-null float64\n",
      " Min Packet Length              692703 non-null int64\n",
      " Max Packet Length              692703 non-null int64\n",
      " Packet Length Mean             692703 non-null float64\n",
      " Packet Length Std              692703 non-null float64\n",
      " Packet Length Variance         692703 non-null float64\n",
      "FIN Flag Count                  692703 non-null int64\n",
      " SYN Flag Count                 692703 non-null int64\n",
      " RST Flag Count                 692703 non-null int64\n",
      " PSH Flag Count                 692703 non-null int64\n",
      " ACK Flag Count                 692703 non-null int64\n",
      " URG Flag Count                 692703 non-null int64\n",
      " ECE Flag Count                 692703 non-null int64\n",
      " Down/Up Ratio                  692703 non-null int64\n",
      " Average Packet Size            692703 non-null float64\n",
      " Avg Fwd Segment Size           692703 non-null float64\n",
      " Avg Bwd Segment Size           692703 non-null float64\n",
      " Fwd Header Length.1            692703 non-null int64\n",
      "Subflow Fwd Packets             692703 non-null int64\n",
      " Subflow Fwd Bytes              692703 non-null int64\n",
      " Subflow Bwd Packets            692703 non-null int64\n",
      " Subflow Bwd Bytes              692703 non-null int64\n",
      "Init_Win_bytes_forward          692703 non-null int64\n",
      " Init_Win_bytes_backward        692703 non-null int64\n",
      " act_data_pkt_fwd               692703 non-null int64\n",
      " min_seg_size_forward           692703 non-null int64\n",
      "Active Mean                     692703 non-null float64\n",
      " Active Std                     692703 non-null float64\n",
      " Active Max                     692703 non-null int64\n",
      " Active Min                     692703 non-null int64\n",
      "Idle Mean                       692703 non-null float64\n",
      " Idle Std                       692703 non-null float64\n",
      " Idle Max                       692703 non-null int64\n",
      " Idle Min                       692703 non-null int64\n",
      " Label                          692703 non-null object\n",
      "dtypes: float64(22), int64(44), object(1)\n",
      "memory usage: 354.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(692703, 67)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# will delete observation if it has any missing values in any of the features.\n",
    "data.dropna()\n",
    "\n",
    "# shape of the data after deleting missing entries\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(692703, 67)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deleting duplicates, except the first observation\n",
    "data.drop_duplicates(keep='first')\n",
    "\n",
    "# shape of the data after deleting duplicate entries\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No missing values and no duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop([' Label'], axis=1)    # 692703 × 66\n",
    "# feeding our target variable to var 'y'\n",
    "y = data[' Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "# 1. Extra-Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing model for feature importance\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# passing the model\n",
    "model = ExtraTreesClassifier(random_state = 53)\n",
    "\n",
    "\n",
    "# training the model\n",
    "model.fit(X, y)\n",
    "\n",
    "# extracting feature importance from model and making a dataframe of it in descending order\n",
    "ETC_feature_importances = pd.DataFrame(model.feature_importances_, index = X.columns, columns=['ETC']).sort_values('ETC', ascending=False)\n",
    "\n",
    "# removing traces of this model\n",
    "model = None\n",
    "\n",
    "# show top 10 features\n",
    "ETC_feature_importances.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Randon-Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing model for feature importance\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# passing the model\n",
    "model = RandomForestClassifier(random_state = 53)\n",
    "\n",
    "# training the model\n",
    "model.fit(X, y)\n",
    "\n",
    "# extracting feature importance from model and making a dataframe of it in descending order\n",
    "RFC_feature_importances = pd.DataFrame(model.feature_importances_, index = X.columns, columns=['RFC']).sort_values('RFC', ascending=False)\n",
    "\n",
    "# removing traces of this model\n",
    "model = None\n",
    "\n",
    "# show top 10 features\n",
    "RFC_feature_importances.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing model for feature importance\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# passing the model\n",
    "model = GradientBoostingClassifier(random_state = 53)\n",
    "\n",
    "# training the model\n",
    "model.fit(X, y)\n",
    "\n",
    "# extracting feature importance from model and making a dataframe of it in descending order\n",
    "GBC_feature_importances = pd.DataFrame(model.feature_importances_, index = X.columns, columns=['GBC']).sort_values('GBC', ascending=False)\n",
    "\n",
    "# removing traces of this model\n",
    "model = None\n",
    "\n",
    "# show top 10 features\n",
    "GBC_feature_importances.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. XGBoost feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature importance manually\n",
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model no training data\n",
    "model = XGBClassifier()\n",
    "model.fit(X, y)\n",
    "# feature importance\n",
    "print(model.feature_importances_)\n",
    "# plot\n",
    "pyplot.bar(range(len(model.feature_importances_)), model.feature_importances_)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature importance using built-in function\n",
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# fit model no training data\n",
    "model = XGBClassifier()\n",
    "model.fit(X, y)\n",
    "# plot feature importance\n",
    "plot_importance(model)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Adaboost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing model for feature importance\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# passing the model\n",
    "model = AdaBoostClassifier(random_state = 53)\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "# extracting feature importance from model and making a dataframe of it in descending order\n",
    "ADB_feature_importances = pd.DataFrame(model.feature_importances_, index = X.columns, columns=['ADB']).sort_values('ADB', ascending=False)\n",
    "\n",
    "# removing traces of this model\n",
    "model = None\n",
    "\n",
    "ADB_feature_importances.head(25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## feeding top 18 features in a variable as dataframe including target variable\n",
    "\n",
    "sample = data[[' Destination Port', 'Init_Win_bytes_forward', ' Average Packet Size', ' Fwd IAT Std', \n",
    "               ' Bwd Packet Length Std', ' Packet Length Std', ' Fwd Packet Length Mean',  \n",
    "               ' Packet Length Mean', ' Bwd Packets/s', 'Bwd Packet Length Max', 'Idle Mean', ' Avg Bwd Segment Size', \n",
    "               'FIN Flag Count', ' Flow IAT Max', ' Flow Duration', ' Total Length of Bwd Packets', ' Min Packet Length', ' Label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(692703, 18)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.shape     # (692703, 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\anacondaa\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "# importing feature scaling function\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# passing range to the function and then save it\n",
    "scaler = MinMaxScaler(feature_range = (0,1))\n",
    "\n",
    "# feeding sample features to var 'X'\n",
    "X = sample.iloc[:,:-1]\n",
    "\n",
    "# feeding our target variable to var 'y'\n",
    "y = sample[' Label']\n",
    "\n",
    "# apply feature scaling to all features\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "#s_sample_2 = scaler.fit_transform(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.22161650e-03, 3.90625000e-03, 3.44563553e-03, ...,\n",
       "        3.19241669e-04, 9.56937799e-09, 4.14364641e-03],\n",
       "       [5.94011025e-03, 4.45571899e-01, 1.19161562e-02, ...,\n",
       "        4.00000003e-06, 5.19936204e-07, 0.00000000e+00],\n",
       "       [1.34377815e-03, 4.45571899e-01, 1.50746554e-01, ...,\n",
       "        9.13333341e-06, 5.02392344e-06, 0.00000000e+00],\n",
       "       ...,\n",
       "       [8.86130072e-01, 1.53656006e-02, 8.67789689e-03, ...,\n",
       "        6.91666672e-07, 9.56937799e-09, 0.00000000e+00],\n",
       "       [8.09320934e-04, 0.00000000e+00, 2.29709035e-02, ...,\n",
       "        8.73863341e-03, 4.08293461e-07, 2.20994475e-02],\n",
       "       [8.09320934e-04, 0.00000000e+00, 2.94155181e-02, ...,\n",
       "        7.91166673e-04, 3.60446571e-07, 3.24585635e-02]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing train-test function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the data in 75%-25% train-test respectively with fixed state\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.25, random_state = 53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(519527, 17) (173176, 17)\n"
     ]
    }
   ],
   "source": [
    "# number of training observation\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173176,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier/ generating classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Xgboost classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.88%\n",
      "Thresh=0.019, n=17, Accuracy: 99.88%\n",
      "Thresh=0.019, n=16, Accuracy: 99.89%\n",
      "Thresh=0.023, n=15, Accuracy: 99.87%\n",
      "Thresh=0.028, n=14, Accuracy: 99.86%\n",
      "Thresh=0.030, n=13, Accuracy: 99.88%\n",
      "Thresh=0.045, n=12, Accuracy: 99.86%\n",
      "Thresh=0.048, n=11, Accuracy: 99.86%\n",
      "Thresh=0.049, n=10, Accuracy: 99.85%\n",
      "Thresh=0.052, n=9, Accuracy: 99.85%\n",
      "Thresh=0.055, n=8, Accuracy: 99.85%\n",
      "Thresh=0.056, n=7, Accuracy: 99.84%\n",
      "Thresh=0.061, n=6, Accuracy: 99.80%\n",
      "Thresh=0.066, n=5, Accuracy: 99.39%\n",
      "Thresh=0.079, n=4, Accuracy: 99.19%\n",
      "Thresh=0.088, n=3, Accuracy: 98.59%\n",
      "Thresh=0.103, n=2, Accuracy: 95.28%\n",
      "Thresh=0.176, n=1, Accuracy: 93.67%\n"
     ]
    }
   ],
   "source": [
    "# use feature importance for feature selection\n",
    "from numpy import loadtxt\n",
    "from numpy import sort\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# fit model on all training data\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "# make predictions for test data and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "# Fit model using each importance as a threshold\n",
    "thresholds = sort(model.feature_importances_)\n",
    "for thresh in thresholds:\n",
    "\t# select features using threshold\n",
    "\tselection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
    "\tselect_X_train = selection.transform(X_train)\n",
    "\t# train model\n",
    "\tselection_model = XGBClassifier()\n",
    "\tselection_model.fit(select_X_train, y_train)\n",
    "\t# eval model\n",
    "\tselect_X_test = selection.transform(X_test)\n",
    "\ty_pred = selection_model.predict(select_X_test)\n",
    "\tpredictions = [round(value) for value in y_pred]\n",
    "\taccuracy = accuracy_score(y_test, predictions)\n",
    "\tprint(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select features using threshold\n",
    "selection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
    "select_X_train = selection.transform(X_train)\n",
    "# train model\n",
    "selection_model = XGBClassifier()\n",
    "selection_model.fit(select_X_train, y_train)\n",
    "# eval model\n",
    "select_X_test = selection.transform(X_test)\n",
    "y_pred = selection_model.predict(select_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting other Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\anacondaa\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "H:\\anacondaa\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "H:\\anacondaa\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1296: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC \n",
    "from sklearn.naive_bayes import BernoulliNB \n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train KNeighborsClassifier Model\n",
    "KNN_Classifier = KNeighborsClassifier(n_jobs=-1)\n",
    "KNN_Classifier.fit(X_train, y_train); \n",
    "\n",
    "# Train LogisticRegression Model\n",
    "LGR_Classifier = LogisticRegression(n_jobs=-1, random_state=0)\n",
    "LGR_Classifier.fit(X_train, y_train);\n",
    "\n",
    "# Train Gaussian Naive Baye Model\n",
    "BNB_Classifier = BernoulliNB()\n",
    "BNB_Classifier.fit(X_train, y_train)\n",
    "            \n",
    "# Train Decision Tree Model\n",
    "DTC_Classifier = tree.DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
    "DTC_Classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate previous models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\anacondaa\\lib\\site-packages\\sklearn\\model_selection\\_split.py:626: Warning: The least populated class in y has only 9 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "H:\\anacondaa\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== Naive Baye Classifier Model Evaluation ==============================\n",
      "\n",
      "Cross Validation Mean Score:\n",
      " 0.6684272265376705\n",
      "\n",
      "Model Accuracy:\n",
      " 0.671204768953298\n",
      "\n",
      "Confusion matrix:\n",
      " [[222926  76395      0      0  30947      0]\n",
      " [   130 123666      0      0  49347      0]\n",
      " [   262   5502      0      0   1931      0]\n",
      " [   758   2315      0      0   1223      0]\n",
      " [  1071    928      0      0   2117      0]\n",
      " [     0      9      0      0      0      0]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.67      0.80    330268\n",
      "           1       0.59      0.71      0.65    173143\n",
      "           2       0.00      0.00      0.00      7695\n",
      "           3       0.00      0.00      0.00      4296\n",
      "           4       0.02      0.51      0.05      4116\n",
      "           5       0.00      0.00      0.00         9\n",
      "\n",
      "   micro avg       0.67      0.67      0.67    519527\n",
      "   macro avg       0.27      0.32      0.25    519527\n",
      "weighted avg       0.83      0.67      0.73    519527\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\anacondaa\\lib\\site-packages\\sklearn\\model_selection\\_split.py:626: Warning: The least populated class in y has only 9 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== Decision Tree Classifier Model Evaluation ==============================\n",
      "\n",
      "Cross Validation Mean Score:\n",
      " 0.9994725948617257\n",
      "\n",
      "Model Accuracy:\n",
      " 0.9998652620556776\n",
      "\n",
      "Confusion matrix:\n",
      " [[330220     46      0      0      2      0]\n",
      " [     2 173137      4      0      0      0]\n",
      " [     0      3   7691      0      1      0]\n",
      " [     2      0      0   4293      1      0]\n",
      " [     2      0      0      7   4107      0]\n",
      " [     0      0      0      0      0      9]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    330268\n",
      "           1       1.00      1.00      1.00    173143\n",
      "           2       1.00      1.00      1.00      7695\n",
      "           3       1.00      1.00      1.00      4296\n",
      "           4       1.00      1.00      1.00      4116\n",
      "           5       1.00      1.00      1.00         9\n",
      "\n",
      "   micro avg       1.00      1.00      1.00    519527\n",
      "   macro avg       1.00      1.00      1.00    519527\n",
      "weighted avg       1.00      1.00      1.00    519527\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\anacondaa\\lib\\site-packages\\sklearn\\model_selection\\_split.py:626: Warning: The least populated class in y has only 9 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== KNeighborsClassifier Model Evaluation ==============================\n",
      "\n",
      "Cross Validation Mean Score:\n",
      " 0.9991376752060294\n",
      "\n",
      "Model Accuracy:\n",
      " 0.9993609571783565\n",
      "\n",
      "Confusion matrix:\n",
      " [[330093    103     31     19     21      1]\n",
      " [    34 173095     12      2      0      0]\n",
      " [    14     12   7662      0      7      0]\n",
      " [    20      3      1   4263      9      0]\n",
      " [    18      1      3     20   4074      0]\n",
      " [     1      0      0      0      0      8]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    330268\n",
      "           1       1.00      1.00      1.00    173143\n",
      "           2       0.99      1.00      0.99      7695\n",
      "           3       0.99      0.99      0.99      4296\n",
      "           4       0.99      0.99      0.99      4116\n",
      "           5       0.89      0.89      0.89         9\n",
      "\n",
      "   micro avg       1.00      1.00      1.00    519527\n",
      "   macro avg       0.98      0.98      0.98    519527\n",
      "weighted avg       1.00      1.00      1.00    519527\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\anacondaa\\lib\\site-packages\\sklearn\\model_selection\\_split.py:626: Warning: The least populated class in y has only 9 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "H:\\anacondaa\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "H:\\anacondaa\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "H:\\anacondaa\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "H:\\anacondaa\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "H:\\anacondaa\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "H:\\anacondaa\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "H:\\anacondaa\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "H:\\anacondaa\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "H:\\anacondaa\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "H:\\anacondaa\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "H:\\anacondaa\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "H:\\anacondaa\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "H:\\anacondaa\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "H:\\anacondaa\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "H:\\anacondaa\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "H:\\anacondaa\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "H:\\anacondaa\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "H:\\anacondaa\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "H:\\anacondaa\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "H:\\anacondaa\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "H:\\anacondaa\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== LogisticRegression Model Evaluation ==============================\n",
      "\n",
      "Cross Validation Mean Score:\n",
      " 0.9582485640587771\n",
      "\n",
      "Model Accuracy:\n",
      " 0.9585084124597951\n",
      "\n",
      "Confusion matrix:\n",
      " [[321907   7954    132    133    142      0]\n",
      " [  1281 171577    106     54    125      0]\n",
      " [  2397   1428   3611    259      0      0]\n",
      " [  2825    451    764    138    118      0]\n",
      " [  2931    447      0      0    738      0]\n",
      " [     9      0      0      0      0      0]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97    330268\n",
      "           1       0.94      0.99      0.97    173143\n",
      "           2       0.78      0.47      0.59      7695\n",
      "           3       0.24      0.03      0.06      4296\n",
      "           4       0.66      0.18      0.28      4116\n",
      "           5       0.00      0.00      0.00         9\n",
      "\n",
      "   micro avg       0.96      0.96      0.96    519527\n",
      "   macro avg       0.60      0.44      0.48    519527\n",
      "weighted avg       0.95      0.96      0.95    519527\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "models = []\n",
    "models.append(('Naive Baye Classifier', BNB_Classifier))\n",
    "models.append(('Decision Tree Classifier', DTC_Classifier))\n",
    "models.append(('KNeighborsClassifier', KNN_Classifier))\n",
    "models.append(('LogisticRegression', LGR_Classifier))\n",
    "\n",
    "for i, v in models:\n",
    "    scores = cross_val_score(v, X_train, y_train, cv=10)\n",
    "    accuracy = metrics.accuracy_score(y_train, v.predict(X_train))\n",
    "    confusion_matrix = metrics.confusion_matrix(y_train, v.predict(X_train))\n",
    "    classification = metrics.classification_report(y_train, v.predict(X_train))\n",
    "    print()\n",
    "    print('============================== {} Model Evaluation =============================='.format(i))\n",
    "    print()\n",
    "    print (\"Cross Validation Mean Score:\" \"\\n\", scores.mean())\n",
    "    print()\n",
    "    print (\"Model Accuracy:\" \"\\n\", accuracy)\n",
    "    print()\n",
    "    print(\"Confusion matrix:\" \"\\n\", confusion_matrix)\n",
    "    print()\n",
    "    print(\"Classification report:\" \"\\n\", classification) \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\anacondaa\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== Naive Baye Classifier Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.6697001894026886\n",
      "\n",
      "Confusion matrix:\n",
      " [[73961 25502     0     0 10300     0]\n",
      " [   40 41309     0     0 16581     0]\n",
      " [   88  1862     0     0   648     0]\n",
      " [  293   783     0     0   424     0]\n",
      " [  373   304     0     0   706     0]\n",
      " [    0     2     0     0     0     0]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.67      0.80    109763\n",
      "           1       0.59      0.71      0.65     57930\n",
      "           2       0.00      0.00      0.00      2598\n",
      "           3       0.00      0.00      0.00      1500\n",
      "           4       0.02      0.51      0.05      1383\n",
      "           5       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.67      0.67      0.67    173176\n",
      "   macro avg       0.27      0.32      0.25    173176\n",
      "weighted avg       0.83      0.67      0.72    173176\n",
      "\n",
      "\n",
      "\n",
      "============================== Decision Tree Classifier Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.9994571996119554\n",
      "\n",
      "Confusion matrix:\n",
      " [[109721     26      9      4      3      0]\n",
      " [    13  57912      5      0      0      0]\n",
      " [     6      7   2584      0      1      0]\n",
      " [     4      0      1   1490      5      0]\n",
      " [     4      0      0      6   1373      0]\n",
      " [     0      0      0      0      0      2]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    109763\n",
      "           1       1.00      1.00      1.00     57930\n",
      "           2       0.99      0.99      0.99      2598\n",
      "           3       0.99      0.99      0.99      1500\n",
      "           4       0.99      0.99      0.99      1383\n",
      "           5       1.00      1.00      1.00         2\n",
      "\n",
      "   micro avg       1.00      1.00      1.00    173176\n",
      "   macro avg       1.00      1.00      1.00    173176\n",
      "weighted avg       1.00      1.00      1.00    173176\n",
      "\n",
      "\n",
      "\n",
      "============================== KNeighborsClassifier Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.9990760844458817\n",
      "\n",
      "Confusion matrix:\n",
      " [[109679     42     16     14     12      0]\n",
      " [    22  57904      3      1      0      0]\n",
      " [    10      8   2579      0      1      0]\n",
      " [     7      0      0   1488      5      0]\n",
      " [    11      0      0      8   1364      0]\n",
      " [     0      0      0      0      0      2]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    109763\n",
      "           1       1.00      1.00      1.00     57930\n",
      "           2       0.99      0.99      0.99      2598\n",
      "           3       0.98      0.99      0.99      1500\n",
      "           4       0.99      0.99      0.99      1383\n",
      "           5       1.00      1.00      1.00         2\n",
      "\n",
      "   micro avg       1.00      1.00      1.00    173176\n",
      "   macro avg       0.99      0.99      0.99    173176\n",
      "weighted avg       1.00      1.00      1.00    173176\n",
      "\n",
      "\n",
      "\n",
      "============================== LogisticRegression Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.9585046426756595\n",
      "\n",
      "Confusion matrix:\n",
      " [[107017   2627     38     39     42      0]\n",
      " [   429  57413     41     14     33      0]\n",
      " [   771    481   1261     85      0      0]\n",
      " [   970    169    272     55     34      0]\n",
      " [   990    149      0      0    244      0]\n",
      " [     2      0      0      0      0      0]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97    109763\n",
      "           1       0.94      0.99      0.97     57930\n",
      "           2       0.78      0.49      0.60      2598\n",
      "           3       0.28      0.04      0.06      1500\n",
      "           4       0.69      0.18      0.28      1383\n",
      "           5       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.96      0.96      0.96    173176\n",
      "   macro avg       0.61      0.44      0.48    173176\n",
      "weighted avg       0.95      0.96      0.95    173176\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\anacondaa\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for i, v in models:\n",
    "    accuracy = metrics.accuracy_score(y_test, v.predict(X_test))\n",
    "    confusion_matrix = metrics.confusion_matrix(y_test, v.predict(X_test))\n",
    "    classification = metrics.classification_report(y_test, v.predict(X_test))\n",
    "    print()\n",
    "    print('============================== {} Model Test Results =============================='.format(i))\n",
    "    print()\n",
    "    print (\"Model Accuracy:\" \"\\n\", accuracy)\n",
    "    print()\n",
    "    print(\"Confusion matrix:\" \"\\n\", confusion_matrix)\n",
    "    print()\n",
    "    print(\"Classification report:\" \"\\n\", classification) \n",
    "    print()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTING FOR TEST DATA using KNN\n",
    "pred_knn = KNN_Classifier.predict(X_scaled)\n",
    "pred_NB = BNB_Classifier.predict(X_scaled)\n",
    "pred_log = LGR_Classifier.predict(X_scaled)\n",
    "pred_dt = DTC_Classifier.predict(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attack Class Distribution\n",
    "data[' Label'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
